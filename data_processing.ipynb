{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing pipeline for eBird data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Walkthrough for data processing steps to build the Birds of a Feather birding partner recommender from eBird observation data.\n",
    "\n",
    "## Contents:\n",
    "1.  Read relevant columns from eBird raw data (obtainable on https://ebird.org/science/download-ebird-data-products) <a href='#step1'> [step 1]</a>\n",
    "2. Group observation by user and extract features for that user <a href='#step2'> [step 2]</a>\n",
    "3. Extract pairs of users <a href='#step3'> [step 3]</a>\n",
    "4. Create georeferenced shapefile with users <a href='#step4'> [step 4]</a>\n",
    "5. Find user names with the eBird API <a href='#step5'> [step 5]</a>\n",
    "6. Scrape user profiles from eBird with a webbot <a href='#step6'> [step 6]</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read raw eBird data <a id='step1'></a>\n",
    "\n",
    "> Reads eBird data *.txt* by chunks using pandas and write chunks to a *.csv* with observations on rows and a subset of columns used for feature extraction by the data processing script. Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: eBird database .txt file muncher [-h] [--input_txt INPUT_TXT]\r\n",
      "                                        [--period PERIOD] [--output OUTPUT]\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --input_txt INPUT_TXT, -i INPUT_TXT\r\n",
      "                        path to eBird database file\r\n",
      "  --period PERIOD, -p PERIOD\r\n",
      "                        start year to end year separated by a dash\r\n",
      "  --output OUTPUT, -o OUTPUT\r\n",
      "                        path to output csv file\r\n"
     ]
    }
   ],
   "source": [
    "!python utils/data_processing/read_ebird.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process eBird data <a id='step2'></a>\n",
    "> Reads oservations *.csv* from previous step, sorts observations by the **OBSERVER ID** column, chunks observations by **OBSERVER ID** and compiles all observation rows for a user into a single row with features for that user. Finding the centroid for a user takes $O(n^{2})$; be advised this may take a considerable time for users with > 100000 observations. See usage below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Script to process eBird observations into user data [-h]\r\n",
      "                                                           [--input_csv INPUT_CSV]\r\n",
      "                                                           [--cores CORES]\r\n",
      "                                                           [--output OUTPUT]\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --input_csv INPUT_CSV, -i INPUT_CSV\r\n",
      "                        path to observations .csv file\r\n",
      "  --cores CORES, -c CORES\r\n",
      "                        number of cores for parallel processing\r\n",
      "  --output OUTPUT, -o OUTPUT\r\n",
      "                        path to output csv file\r\n"
     ]
    }
   ],
   "source": [
    "!python utils/data_processing/process_ebird.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract pairs of users <a id='step3'></a>\n",
    "> Reads observation *.csv* file from step 1 and user features from step 2 to create a *.csv* with a subset of users that have paired eBird activity. Pairs are found looking for users that share a unique **GROUP IDENTIFIER** from the observations data. Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Script to get all pairs of users within observations\r\n",
      "       [-h] [--input_obs INPUT_OBS] [--input_users INPUT_USERS]\r\n",
      "       [--cores CORES] [--output OUTPUT]\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --input_obs INPUT_OBS, -i INPUT_OBS\r\n",
      "                        path to observations .csv file\r\n",
      "  --input_users INPUT_USERS, -u INPUT_USERS\r\n",
      "                        path to users .csv file\r\n",
      "  --cores CORES, -c CORES\r\n",
      "                        number of cores for parallel processing\r\n",
      "  --output OUTPUT, -o OUTPUT\r\n",
      "                        path to output csv file\r\n"
     ]
    }
   ],
   "source": [
    "!python utils/data_processing/extract_pairs.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create georeferenced dataset <a id='step4'></a>\n",
    "> Converts latitude and longitude columns from step 2 *.csv* with user features DataFrame into shapely Points. Writes new data frame as *.shp* file readable by GIS software and geopandas. Used to filter matches by distance in the app. See usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: copies a .csv dataframe with latitude and longitude columns into a GIS shapefile\r\n",
      "       [-h] [--input_csv INPUT_CSV] [--output_shp OUTPUT_SHP]\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --input_csv INPUT_CSV, -i INPUT_CSV\r\n",
      "                        Path to .csv file.\r\n",
      "  --output_shp OUTPUT_SHP, -o OUTPUT_SHP\r\n",
      "                        path to output shapefile\r\n"
     ]
    }
   ],
   "source": [
    "!python utils/data_processing/get_shapefile.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Find user names using eBird API <a id='step5'></a>\n",
    "> Uses checklist identifiers from user features (step 2) to find user profile names with the eBird API and add them to the georeferenced dataset (step 4). See usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Adds users ID column to users shapefile [-h] [--users_shp USERS_SHP]\r\n",
      "                                               [--counties_shp COUNTIES_SHP]\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --users_shp USERS_SHP, -u USERS_SHP\r\n",
      "                        path to users shapefile\r\n",
      "  --counties_shp COUNTIES_SHP, -c COUNTIES_SHP\r\n",
      "                        path to counties shapefile\r\n"
     ]
    }
   ],
   "source": [
    "!python utils/data_processing/add_user_names.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Scrape user profiles from eBird <a id='step6'></a>\n",
    "> Uses webbot, checklist identifiers from step 2 and user profile names from step 5 to find links to public user profile for each user. Defaults to the unique checklist IDs when profiles are not found (only ~25% of eBird users currently have public profiles). Profile column added to *.shp* file from step 4 and is provided to recommendations. See usage: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: Uses webbot to extract user profile urls from ebird [-h]\r\n",
      "                                                           [--input_users INPUT_USERS]\r\n",
      "                                                           [--output_txt OUTPUT_TXT]\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --input_users INPUT_USERS, -i INPUT_USERS\r\n",
      "                        path to users dataframe with checklist IDs to search\r\n",
      "                        for profiles\r\n",
      "  --output_txt OUTPUT_TXT, -o OUTPUT_TXT\r\n",
      "                        path to .txt file where user profile urls will be\r\n",
      "                        written to\r\n"
     ]
    }
   ],
   "source": [
    "!python utils/data_processing/get_ebird_profile.py -h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:birding]",
   "language": "python",
   "name": "conda-env-birding-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
